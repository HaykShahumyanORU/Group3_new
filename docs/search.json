[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Group3",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nIt holds all the data for group 3",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "Hayk.html",
    "href": "Hayk.html",
    "title": "1  Hayk",
    "section": "",
    "text": "1.1 Week 1\nExcel",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#week-1",
    "href": "Hayk.html#week-1",
    "title": "1  Hayk",
    "section": "",
    "text": "1.1.1 Wednesday\nI spent about 30 mins to an hour working through the VIZ_basic-excel-web excel practice page and did everything until the homework tab which requires me to do a different data set. So all steps 1 through 6 including all the basic functions, how to filter out tools that were not necessary, how to adjust inputted graphs and visualizations, and how to add in all the different visualizations were completed.\nsince this was my first time learning how to use quarto after finishing all the excel practices from Monday, I have not explained each individual tool I practiced since I have completed them all already.\n\n\n\n1.1.2 Friday\nToday I have chosen my data set. My data set has a large collection of data, which holds data of modeled medium and heavy duty vehicle with info on their stock, sales, energy consumption, greenhouse gas emissions, and total cost of driving. I have chosen to do vehicle sales as my dataset for today. Chatgpt recommends these areas for the inserts 1. Total Vehicle Sales by Year and Vehicle Class\nGraph Type: Stacked Bar Chart\nPurpose: This will show how the sales of different vehicle classes contribute to the total sales each year, and how the sales have changed over the years.\nX-axis: Year (2023, 2024, 2025, 2026)\nY-axis: Vehicle Sales (in thousands)\nStacked Bars: Light-Medium (Class 3), Medium (Classes 4-6), Heavy (Classes 7-8)\n\nTrend of Vehicle Sales by Vehicle Class Over Time\nGraph Type: Line Chart Purpose: To visualize the trend of sales for each vehicle class over the years. X-axis: Year (2023, 2024, 2025, 2026) Y-axis: Vehicle Sales (in thousands) Lines: Separate lines for Light-Medium (Class 3), Medium (Classes 4-6), and Heavy (Classes 7-8)\nYearly Distribution of Vehicle Sales Across Classes\nGraph Type: Pie Charts (for each year) Purpose: To show the percentage share of each vehicle class in total sales for each year. Slices: Light-Medium (Class 3), Medium (Classes 4-6), Heavy (Classes 7-8)\nComparison of Vehicle Sales Growth Between Classes\nGraph Type: Grouped Bar Chart Purpose: To compare how much each vehicle class has grown or declined in sales from year to year. X-axis: Year (2023, 2024, 2025, 2026) Y-axis: Vehicle Sales (in thousands) Bars: Separate bars for Light-Medium (Class 3), Medium (Classes 4-6), and Heavy (Classes 7-8), grouped by year.\nSales Proportion Change Over Years for Each Vehicle Class\nGraph Type: 100% Stacked Area Chart Purpose: To show how the proportion of sales for each vehicle class has changed over the years. X-axis: Year (2023, 2024, 2025, 2026) Y-axis: Percentage of Total Sales (%) Areas: Light-Medium (Class 3), Medium (Classes 4-6), Heavy (Classes 7-8)\n\nRecommended Chart: Total Vehicle Sales by Year and Vehicle Class (Stacked Bar Chart)\nThis chart provides a clear visual comparison of vehicle sales over the years and how each class contributes to the total sales.\n\nthis graph shows us that the light-medium vehicles are the ones that were sold the most from the large amount of data",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#week-2",
    "href": "Hayk.html#week-2",
    "title": "1  Hayk",
    "section": "1.2 Week 2",
    "text": "1.2 Week 2\n\n1.2.1 Wednesday\n\n1.2.1.1 Histogram\nI am using the airquality dataset, which is …\nI use excel to clean the data, remove all the rows which have NA values, and I did an exploration analysis\n\n\n1.2.1.2 Ozone Histogram\n\n\n\n1.2.1.3 Ozone vs Temp\n #### which day out of all the months had the most solar R\n\n\n\n\n1.2.2 friday\nToday I am learning about pivot charts which are extended from pivot tables. To get to my insert chart I selected all of my pivot table and near the insert tab there was an option for a pivot chart.\n\nThis graph shows how for each day for each month, the ratio of each value. For example, for each month you can start to see the temperature changes between each day within each month. You can see which days have more average Ozone, and which days have an increase of solar Radiation. We can see how when there is an increase in temperature, there is less solar radiation which I find interesting. there was a day on the 8th month where there seemed to be no solar radiation and only an increased average temp and increased ozone.\n\nThis pivot table and pivot chart for my data is representing how much of the market is taken up by which type of vehicles. We can see visually that generally, there is a trend that the shorter the distance for the commercial vehicles, the more of those types of vehicles are bought. My data for this week is the vehicle stock. The X line represents how much vehicles are sold, while the Y line lists the amount of miles expected for that commercial vehicle type.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#week-3",
    "href": "Hayk.html#week-3",
    "title": "1  Hayk",
    "section": "1.3 Week 3",
    "text": "1.3 Week 3\n\n1.3.1 Wednesday\nA data frame with 20 observations on 3 variables.\n[, 1] extra numeric increase in hours of sleep [, 2] group factor drug given [, 3] ID factor patient ID\nUsing the sleep dataset to create my first dashboard\nhttps://public.tableau.com/app/profile/hayk.shahumyan/viz/Wednesdayweek3/Dashboard1\n\n\n1.3.2 Friday\nI plan to work on fuel costs of vehicles of projected till 2040\nFormat\nThere are 3 variables we focus on: cost of electricity cost of diesel cost of hydrogen from now till 2050\nDetails\nWe can see trends of downward prices of electricity and hydrogen, while diesel is mostly stable in price\nhttps://public.tableau.com/app/profile/hayk.shahumyan/viz/Week3Friday-Saturday/Dashboard1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#week-4",
    "href": "Hayk.html#week-4",
    "title": "1  Hayk",
    "section": "1.4 Week 4",
    "text": "1.4 Week 4\n\n1.4.1 Wednesday and Friday",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#this-is-a-markdown-title",
    "href": "Hayk.html#this-is-a-markdown-title",
    "title": "1  Hayk",
    "section": "1.5 This is a markdown title",
    "text": "1.5 This is a markdown title\nin markdown we can create lists:\n\nItem 1\nitem 2\nitem 3\n\nalso we can create enumerated list\n\nHola\nHi\nNamaste\n\nwe can do bold, also italic\n# Here we are importing numpy with a nickname np\nimport numpy as np\nprint(np.absolute(-1))\narr = np.array([1, 2, 3, 4, 5])\nprint(arr)\n1\n[1 2 3 4 5]\n#List are native to python\nmy_list = [1, 2, 3, 4, 5]\nprint(my_list)\n[1, 2, 3, 4, 5]\n# We will be using a lot of dataframes, so we need pandas library\nimport pandas as pd\ndata = {'Ozone': [41, 36, 12], 'Temp': [67, 72, 74]}\ndf = pd.DataFrame(data)\nprint(df)\n   Ozone  Temp\n0     41    67\n1     36    72\n2     12    74",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#loading-csv-files",
    "href": "Hayk.html#loading-csv-files",
    "title": "1  Hayk",
    "section": "1.6 4. Loading csv Files",
    "text": "1.6 4. Loading csv Files\nTo load .csv files into a DataFrame, we use the pandas function read_csv:\ndf = pd.read_csv('airquality_datasets.csv')\nprint(df.info())\nprint(df.describe())\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 153 entries, 0 to 152\nData columns (total 6 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Ozone    116 non-null    float64\n 1   Solar.R  146 non-null    float64\n 2   Wind     153 non-null    float64\n 3   Temp     153 non-null    int64  \n 4   Month    153 non-null    int64  \n 5   Day      153 non-null    int64  \ndtypes: float64(3), int64(3)\nmemory usage: 7.3 KB\nNone\n            Ozone     Solar.R        Wind        Temp       Month         Day\ncount  116.000000  146.000000  153.000000  153.000000  153.000000  153.000000\nmean    42.129310  185.931507    9.957516   77.882353    6.993464   15.803922\nstd     32.987885   90.058422    3.523001    9.465270    1.416522    8.864520\nmin      1.000000    7.000000    1.700000   56.000000    5.000000    1.000000\n25%     18.000000  115.750000    7.400000   72.000000    6.000000    8.000000\n50%     31.500000  205.000000    9.700000   79.000000    7.000000   16.000000\n75%     63.250000  258.750000   11.500000   85.000000    8.000000   23.000000\nmax    168.000000  334.000000   20.700000   97.000000    9.000000   31.000000",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#visualizing-the-dataset",
    "href": "Hayk.html#visualizing-the-dataset",
    "title": "1  Hayk",
    "section": "1.7 5. visualizing the dataset",
    "text": "1.7 5. visualizing the dataset\nLet’s dive into visualizations using matplotlib. We’ll start with simple histograms and boxplots, then move on to correlation plots. Histograms\nHistograms help us understand the distribution of the variables. We’ll create histograms for Ozone and Temp.\nimport matplotlib.pyplot as plt\n\n# Ozone Histogram\nplt.figure(figsize=(8, 6))\nplt.hist(df['Ozone'].dropna(), bins=20, color='blue', edgecolor='black')\nplt.title('Distribution of Ozone Levels')\nplt.xlabel('Ozone (ppb)')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\npng\n\n\n\n# Temp Histogram\nplt.figure(figsize=(8, 6))\nplt.hist(df['Temp'].dropna(), bins=20, color='orange', edgecolor='black')\nplt.title('Distribution of Temperature')\nplt.xlabel('Temperature (°F)')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\npng",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#week-5",
    "href": "Hayk.html#week-5",
    "title": "1  Hayk",
    "section": "1.8 Week 5",
    "text": "1.8 Week 5",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#week-after-fall-break",
    "href": "Hayk.html#week-after-fall-break",
    "title": "1  Hayk",
    "section": "1.9 Week after fall break",
    "text": "1.9 Week after fall break",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#second-semester-schedule",
    "href": "Hayk.html#second-semester-schedule",
    "title": "1  Hayk",
    "section": "1.10 Second semester schedule",
    "text": "1.10 Second semester schedule\nAll charts made in r studio or shiny and 1-3 sentence summary with each visualization\nNov 2: create a dual-line chart comparing number of work stoppages beginning and number of work stoppages in effect\nNov 9: create a stacked area chart comparing workers involved beginning and workers involved in effect\nNov 16: create a scatter plot comparing days of idleness and percent total working time\nNov 23: create a bubble chart comparing number of work stoppages beginning, workers involved beginning and days of idleness\nNov 30: create a 3D scatter plot comparing the number of work stoppages in effect, workers involved in effect, and percent total working time\n(For this weeks assignment, everyone needed to find a dataset from our datasource and give a summary about it.)\nhttps://www.bls.gov/wsp/overview.htm\nThe data provides a historical record of annual work stoppages in the U.S. involving 1,000 or more workers, starting from 1947. It includes the following key information:\nThe year of the work stoppage.\nThe number of work stoppages that began in a given year and those still in effect.\nThe number of workers involved (in thousands).\nThe number of days of idleness (in thousands) caused by these stoppages.\nThe percentage of total working time lost due to these stoppages.\nThis dataset is focused on capturing the frequency and economic impact of large-scale labor disruptions over time.\ndirect summary from the website:\nThe Bureau of Labor Statistics has two types of data about work stoppages: Work Stoppages program data and the Strike Report.\nThe Work Stoppages program provides monthly and annual data of major work stoppages involving 1,000 or more workers lasting one full shift or longer. The monthly and annual data show the establishment and union(s) involved in the work stoppage along with the location, the number of workers and the days of idleness. The monthly data list all work stoppages involving 1,000 or more workers that occurred during the full calendar month for each month of the year. The annualized data provide statistics, analysis and details of each work stoppage of 1,000 or more workers that occurred during the year. The work stoppages data are gathered from public news sources, such as newspapers and the Internet. The BLS does not distinguish between strikes and lock-outs in the data; both are included in the term “work stoppages”.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#oct-28th",
    "href": "Hayk.html#oct-28th",
    "title": "1  Hayk",
    "section": "1.11 oct 28th",
    "text": "1.11 oct 28th\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(readxl)\n\n# Load the dataset\ndata4 &lt;- read_excel(\"cleaned_annual_listing.xlsx\", sheet = \"Sheet1\")\n\n# Ensure Year column is numeric and remove NA values\ndata4$Year &lt;- as.numeric(data4$Year)\n\nWarning: NAs introduced by coercion\n\ndata4 &lt;- data4[!is.na(data4$Year), ]\n\n# Create a dual-line chart with adjusted x-axis labels\nggplot(data4, aes(x = Year)) +\n  geom_line(aes(y = Number_of_Work_Stoppages_Beginning, color = \"Work Stoppages Beginning\", group = 1), na.rm = TRUE) +\n  geom_line(aes(y = Number_of_Work_Stoppages_In_Effect, color = \"Work Stoppages In Effect\", group = 1), na.rm = TRUE) +\n  labs(title = \"Comparison of Work Stoppages Beginning and In Effect Over the Years\",\n       x = \"Year\",\n       y = \"Number of Work Stoppages\",\n       color = \"Legend\") +\n  theme_minimal() +\n  scale_x_continuous(breaks = seq(min(data4$Year, na.rm = TRUE), max(data4$Year, na.rm = TRUE), by = 5)) + # Show every 5th year\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels\n\n\n\n\n\n\n\n\nThe graph shows a clear decline in the number of work stoppages that both began and were in effect over the years, especially prominent from the mid-20th century onward. The “Work Stoppages Beginning” generally tracked slightly above “Work Stoppages In Effect,” but both followed a similar downward trend. This decline may indicate changes in labor practices, regulations, or economic conditions affecting work stoppages over time.\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(readxl)\nlibrary(tidyr)\n\n# Replace with your data loading path if needed\ndata &lt;- read_excel(\"cleaned_annual_listing.xlsx\", sheet = \"Sheet1\")\n\n# Clean and select necessary columns\ndata &lt;- data[3:nrow(data), c(1, 4, 5)]  # Adjust to skip header rows and select Year, Workers_Beginning, Workers_Effect\ncolnames(data) &lt;- c(\"Year\", \"Workers_Beginning\", \"Workers_Effect\")\n\n# Convert columns to appropriate types\ndata$Year &lt;- as.integer(gsub(\"\\\\D\", \"\", data$Year))\ndata$Workers_Beginning &lt;- as.numeric(gsub(\",\", \"\", data$Workers_Beginning))\ndata$Workers_Effect &lt;- as.numeric(gsub(\",\", \"\", data$Workers_Effect))\n\n# Reshape data for ggplot\ndata_long &lt;- pivot_longer(data, cols = c(\"Workers_Beginning\", \"Workers_Effect\"), names_to = \"Status\", values_to = \"Workers\")\n\n# Plot the stacked area chart\nggplot(data_long, aes(x = Year, y = Workers, fill = Status)) +\n  geom_area(alpha = 0.6) +\n  labs(title = \"Comparison of Workers Involved at Beginning vs. In Effect\", \n       x = \"Year\", \n       y = \"Number of Workers (in thousands)\") +\n  scale_fill_manual(values = c(\"Workers_Beginning\" = \"blue\", \"Workers_Effect\" = \"green\")) +\n  theme_minimal()\n\nWarning: Removed 42 rows containing non-finite outside the scale range\n(`stat_align()`).\n\n\n\n\n\n\n\n\n\nThis chart compares the number of workers involved in work stoppages at the beginning of the period (blue) versus those who remained involved (green) across several years. The high blue peaks show that a large number of workers were initially involved in stoppages, but the much smaller green areas indicate that far fewer workers were still involved as stoppages continued. This suggests a pattern where many workers initially participate in stoppages, but the number decreases over time.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Hayk.html#nov-16th",
    "href": "Hayk.html#nov-16th",
    "title": "1  Hayk",
    "section": "1.12 nov 16th",
    "text": "1.12 nov 16th\n\n# Load necessary library\nlibrary(readxl)\nlibrary(ggplot2)\n\n# Read the data from the Excel file\nfile_path &lt;- \"cleaned_annual_listing.xlsx\"\ndata &lt;- read_excel(file_path, sheet = \"Sheet1\")\n\n# Create a scatter plot\nggplot(data, aes(x = `Days_of_Idleness`, y = `Percent_Total_Working_Time`)) +\n  geom_point() +\n  labs(\n    title = \"Scatter Plot of Days of Idleness vs. Percent Total Working Time\",\n    x = \"Days of Idleness\",\n    y = \"Percent Total Working Time\"\n  ) +\n  theme_minimal()\n\nWarning: Removed 20 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThe scatter plot visualizes the relationship between “Days of Idleness” and “Percent Total Working Time.” Each point represents a year, with its position showing the level of work stoppage (days of idleness) and its impact on the overall working time percentage. If there is a positive trend (points forming an upward slope), it indicates that higher days of idleness are associated with a greater percentage impact on total working time, suggesting a correlation between increased stoppages and reduced productivity.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Hayk</span>"
    ]
  },
  {
    "objectID": "Pratiti.html",
    "href": "Pratiti.html",
    "title": "2  Pratiti",
    "section": "",
    "text": "2.1 Week 1\nExcel",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#week-1",
    "href": "Pratiti.html#week-1",
    "title": "2  Pratiti",
    "section": "",
    "text": "2.1.1 Wednesday\n\n2.1.1.1 Basic Functions\nI can now use sum, average, and more functions to select a whole row and make the process more efficient for large datasets.\n\n\n2.1.1.2 Basic Visualizations\nThrough using the insert tab, I learned how to choose to represent data with a scatterplot, line plot, bar chart, and more. To customize and format the histogram is easily done in Excel. Each axis can be labeled for the person viewing to understand.\n\n\n2.1.1.3 Scatter Plot\n\nFrom the Dataset, we see a trend that as the age of the tree increases, the circumference also increases. This is consistent for different types of trees and helps us see into history of how long a tree survived. Another method is also to count the rings once the tree is cut down. However, using the circumference gives a qualitative measurement of when the tree can still be alive and aged.\n\n\n\n2.1.2 Friday\nThe US Bureau of Labor and Statistics offers many data sets to do with the work force in America. This data is found from civilian unemployment rates over the past 10 years including people of different ethnicity.\n\nThe visualization shows there is a peak in unemployment rate in the year 2020-2021 when Covid-19 affected everyday lives of civilians. This graph represents the unemployment dramatic decrease during the pandemic, but also stabilization in 2022.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#week-2",
    "href": "Pratiti.html#week-2",
    "title": "2  Pratiti",
    "section": "2.2 Week 2",
    "text": "2.2 Week 2\n\n2.2.1 Wednesday\n\n2.2.1.1 Histogram\nI am using the air quality data set which is shows the ozone ppm distribution based on temperature, month and day. Th data was obtained from the New York State Department of Conservation and the National Weather Service. The temperature was taking as the maximum daily temperature at LaGuardia airport. The mean ozone is measured in parts per billion from 13:00 to 15:00 at Roosevelt Island.\nI used excel to clean the data through filtration by removing the NA values. I then did exploration analysis.\n\n\n2.2.1.2 Ozone Histogram\n\n\n\n2.2.1.3 Ozone vs. Temp Scatterplot\n\n\n\n2.2.1.4 My First Pivot Table\n\nThis table shows the difference in averages of ozone in May versus September. The trend shows that the average seems to be higher at the start of the month and decreases gradually. In September there is a general trend of higher ozone levels per day compared to May. This trend may reveal something new about the ozone levels and air quality.\n\n\n\n2.2.2 Friday\nU.S. Bureau of Labor Statistics\nThe Consumer Expenditure Surveys (CE) are national studies by the U.S. Bureau of Labor Statistics (BLS) that examine how people in the U.S. spend their money. The CE includes two types of surveys: the Interview Survey and the Diary Survey. The Interview Survey gathers information about significant or ongoing expenses that people can remember over a period of 3 months or more, including large purchases like homes and cars or regular payments like rent and utilities.\nCE data are valuable for both government and private organizations that focus on specific population groups, including the elderly, low-income families, urban residents, and individuals receiving Supplemental Nutrition Assistance Program (SNAP) benefits. Economic policymakers use this data to evaluate how policy changes affect living standards among various socioeconomic groups, while econometricians leverage it to build models for predicting economic outcomes.\nI plan to break up all the parts of the data to the main sections to compare how much consumers spend on each category in life.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#week-3",
    "href": "Pratiti.html#week-3",
    "title": "2  Pratiti",
    "section": "2.3 Week 3",
    "text": "2.3 Week 3\n\n2.3.1 Wednesday\n\n2.3.1.1 Orchard Sprays\nAn experiment was conducted to evaluate the effectiveness of various orchard spray components in repelling honeybees, using a Latin square design. In this experiment, dry comb cells were filled with specific amounts of lime sulfur emulsion mixed in sucrose solution. Seven concentrations of lime sulfur were tested, ranging from 1/100 to 1/1,562,500, with each concentration decreasing by factors of 1/5, along with a control solution containing no lime sulfur. A had the highest level of lime sulpher while H had no lime sulphur. To assess the bees’ responses, 100 bees were released into a chamber for two hours, and the decrease in solution volume in each cell was measured to determine the repellency of the different concentrations.\nDashboard on Tableau\n\n\n\n2.3.2 Friday\n\nPratiti will work on employment and wages in different states collectively -\n\nThe Quarterly Census of Employment and Wages (QCEW) provides detailed employment and wage data across various industries, states, and the entire U.S. For the first quarter of 2024, the dataset encompasses private sector employment and wages across all industries and establishment sizes. This comprehensive dataset, sourced from the Bureau of Labor Statistics, allows for an in-depth analysis of employment trends and wage patterns nationwide. The QCEW data is instrumental in understanding the economic landscape, providing valuable insights into employment distribution and wage structures across different sectors and regions.\nDashboard on Tableau",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#week-4",
    "href": "Pratiti.html#week-4",
    "title": "2  Pratiti",
    "section": "2.4 Week 4",
    "text": "2.4 Week 4\n\n2.4.1 Wednesday and Friday",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#this-is-a-markdown-title",
    "href": "Pratiti.html#this-is-a-markdown-title",
    "title": "2  Pratiti",
    "section": "2.5 This is a markdown title",
    "text": "2.5 This is a markdown title\nin markdown we can create lists:\n\nitem 1\nitem 2\nitem 3\n\nalso we can create enumerated list\n\nHola\nHi\nNamaste\n\nwe can do bold, also italic\n# Here we are importing numpy with a nickname np\nimport numpy as np\nprint(np.absolute(-1))\narr = np.array([1, 2, 3, 4, 5])\nprint(arr)\n1\n[1 2 3 4 5]\n# lists are native to python\nmy_list = [1, 2, 3, 4, 5]\nprint(my_list)\n[1, 2, 3, 4, 5]\n# We will be using a lot of dataframes, so we need pandas library.\nimport pandas as pd\ndata = {'Ozone': [41, 36, 12], 'Temp': [67, 72, 74]}\ndf = pd.DataFrame(data)\nprint(df)\n   Ozone  Temp\n0     41    67\n1     36    72\n2     12    74",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#loading-csv-files",
    "href": "Pratiti.html#loading-csv-files",
    "title": "2  Pratiti",
    "section": "2.6 4. Loading csv files",
    "text": "2.6 4. Loading csv files\nTo load csv files into a DataFrame, we use the pandas function read_csv:\ndf = pd.read_csv('airquality_datasets.csv')\nNow, let’s load and explore the summary of the airquality dataset.\n# Summary of data frame\nprint(df.info())\nprint(df.describe())\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 153 entries, 0 to 152\nData columns (total 6 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Ozone    116 non-null    float64\n 1   Solar.R  146 non-null    float64\n 2   Wind     153 non-null    float64\n 3   Temp     153 non-null    int64  \n 4   Month    153 non-null    int64  \n 5   Day      153 non-null    int64  \ndtypes: float64(3), int64(3)\nmemory usage: 7.3 KB\nNone\n            Ozone     Solar.R        Wind        Temp       Month         Day\ncount  116.000000  146.000000  153.000000  153.000000  153.000000  153.000000\nmean    42.129310  185.931507    9.957516   77.882353    6.993464   15.803922\nstd     32.987885   90.058422    3.523001    9.465270    1.416522    8.864520\nmin      1.000000    7.000000    1.700000   56.000000    5.000000    1.000000\n25%     18.000000  115.750000    7.400000   72.000000    6.000000    8.000000\n50%     31.500000  205.000000    9.700000   79.000000    7.000000   16.000000\n75%     63.250000  258.750000   11.500000   85.000000    8.000000   23.000000\nmax    168.000000  334.000000   20.700000   97.000000    9.000000   31.000000",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#vizualizing-the-dataset",
    "href": "Pratiti.html#vizualizing-the-dataset",
    "title": "2  Pratiti",
    "section": "2.7 5. Vizualizing the dataset",
    "text": "2.7 5. Vizualizing the dataset\nLet’s dive into visualizations using matplotlib. We’ll start with simple histograms and boxplots, then move on to correlation plots.\n\n2.7.1 Histograms\nHistograms help us understand the distribution of the variables. We’ll create histograms for Ozone and Temp.\nimport matplotlib.pyplot as plt\n\n# Ozone Histogram\nplt.figure(figsize=(8, 6))\nplt.hist(df['Ozone'].dropna(), bins=20, color='blue', edgecolor='black')\nplt.title('Distribution of Ozone Levels')\nplt.xlabel('Ozone (ppb)')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\npng\n\n\n# Temp Histogram\nplt.figure(figsize=(8, 6))\nplt.hist(df['Temp'].dropna(), bins=20, color='orange', edgecolor='black')\nplt.title('Distribution of Temperature')\nplt.xlabel('Temperature (°F)')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\npng",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#boxplots",
    "href": "Pratiti.html#boxplots",
    "title": "2  Pratiti",
    "section": "2.8 Boxplots",
    "text": "2.8 Boxplots\nBoxplots are useful for identifying outliers and understanding the spread of the data.\n# Boxplot for Ozone\nplt.figure(figsize=(8, 6))\nplt.boxplot(df['Ozone'].dropna())\nplt.title('Boxplot of Ozone Levels')\nplt.ylabel('Ozone (ppb)')\nplt.show()\n\n# Boxplot for Temp\nplt.figure(figsize=(8, 6))\nplt.boxplot(df['Temp'].dropna())\nplt.title('Boxplot of Temperature')\nplt.ylabel('Temperature (°F)')\nplt.show()\n\n\n\npng\n\n\n\n\n\npng",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#correlation-plots",
    "href": "Pratiti.html#correlation-plots",
    "title": "2  Pratiti",
    "section": "2.9 Correlation Plots",
    "text": "2.9 Correlation Plots\nNext, we can explore the correlation between Ozone and Temp, using Month as a categorical variable.\nimport seaborn as sns\n\n# Scatter plot with regression line\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='Temp', y='Ozone', hue='Month', data=df)\nplt.title('Temperature vs Ozone Levels by Month')\nplt.xlabel('Temperature (°F)')\nplt.ylabel('Ozone (ppb)')\nplt.show()\n\n# Correlation matrix\ncorr = df[['Ozone', 'Temp', 'Wind']].corr()\nsns.heatmap(corr, annot=True, cmap='coolwarm')\nplt.title('Correlation Matrix')\nplt.show()\n\n\n\npng\n\n\n\n\n\npng",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#week-5",
    "href": "Pratiti.html#week-5",
    "title": "2  Pratiti",
    "section": "2.10 Week 5",
    "text": "2.10 Week 5",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#second-semester-schedule",
    "href": "Pratiti.html#second-semester-schedule",
    "title": "2  Pratiti",
    "section": "10.1 Second semester schedule",
    "text": "10.1 Second semester schedule\nAll charts made in r studio or shiny and 1-3 sentence summary with each visualization\nNov 2: create a box plot comparing educational attainment and median usual weekly earnings\nNov 9: create a bar chart comparing educational attainment and unemployment rate\nNov 16: create a scatter plot comparing median usual weekly earnings and unemployment rate\nNov 23: create a heatmap comparing total fatal injuries and industry\nNov 30: create a dot plot comparing fatal injury causes and industry\n(For this weeks assignment, everyone needed to find a dataset from our datasource and give a summary about it.)\nhttps://www.bls.gov/emp/tables/unemployment-earnings-education.htm\nIn 2023, data from the Bureau of Labor Statistics highlights a strong link between educational attainment, earnings, and unemployment rates. Individuals with higher levels of education tend to earn more and face lower unemployment. Those with advanced degrees, such as doctoral or professional degrees, have the highest median weekly earnings, over $2,100, and the lowest unemployment rates, under 2%. Master’s degree holders also enjoy relatively high earnings of $1,737 per week, with a low 2.0% unemployment rate. Bachelor’s degree holders earn $1,493 weekly with a 2.2% unemployment rate.\nAs educational attainment decreases, so do earnings, while unemployment rates rise. Individuals with an associate’s degree earn $1,058 per week with a 2.7% unemployment rate, while those with some college but no degree earn $992 weekly with a 3.3% unemployment rate. High school graduates see further declines, earning $899 per week with a 3.9% unemployment rate. Those with less than a high school diploma face the greatest challenges, with the lowest median earnings of $708 per week and the highest unemployment rate of 5.6%. Overall, education plays a key role in determining both income potential and job stability.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#oct-28th",
    "href": "Pratiti.html#oct-28th",
    "title": "2  Pratiti",
    "section": "10.2 Oct 28th",
    "text": "10.2 Oct 28th\n\nlibrary(plotly)\n\nLoading required package: ggplot2\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(ggplot2)\n\n\n# Load necessary libraries\nlibrary(plotly)\n\n# Import the dataset\ndata &lt;- read.csv(\"education.csv\", header = TRUE, stringsAsFactors = FALSE, na.strings = c(\"\", \"NA\"))\n\n# Ensure relevant columns are numeric and clean them\ndata$`Unemployment.rate....` &lt;- as.numeric(gsub(\",\", \"\", as.character(data$`Unemployment.rate....`)))\n\n# Check for NAs after conversion\nna_count &lt;- sum(is.na(data$`Unemployment.rate....`))\nif (na_count &gt; 0) {\n  cat(\"Number of NA values in unemployment rate:\", na_count, \"\\n\")\n}\n\nNumber of NA values in unemployment rate: 1 \n\n# Filter out rows where unemployment rate is NA\nfiltered_data &lt;- data[!is.na(data$`Unemployment.rate....`), ]\n\n# Sort the data by unemployment rate from lowest to highest\nfiltered_data &lt;- filtered_data[order(filtered_data$`Unemployment.rate....`), ]\n\n# Check if the filtered data is empty\nif (nrow(filtered_data) == 0) {\n  stop(\"Filtered data is empty. Please check the dataset for valid unemployment rate values.\")\n}\n\n# Create the scatter plot using Plotly\nfig &lt;- plot_ly(\n  data = filtered_data,\n  x = ~`Educational.attainment`,\n  y = ~`Unemployment.rate....`,\n  type = 'scatter',\n  mode = 'markers',\n  marker = list(\n    color = ~`Unemployment.rate....`,  # Color based on unemployment rate\n    colorscale = 'Reds',               # Color scale\n    showscale = TRUE,                  # Show color scale\n    size = 10                          # Size of the points\n  )\n) %&gt;%\n  layout(\n    title = \"Scatter Plot of Educational Attainment vs. Unemployment Rate\",\n    xaxis = list(title = \"Educational Attainment\"),\n    yaxis = list(title = \"Unemployment Rate (%)\"),\n    showlegend = FALSE\n  )\n\n# Show the plot\nfig\n\n\n\n\n\nThe scatter plot illustrates the relationship between educational attainment and unemployment rates, showcasing how higher levels of education are generally associated with lower unemployment. Each point represents a specific educational category, with color intensity reflecting the unemployment rate—darker shades indicating higher rates. This visual, sourced from the Bureau of Labor Statistics (BLS), emphasizes the importance of education in influencing job market outcomes, highlighting that individuals with higher educational qualifications tend to experience greater job stability.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Pratiti.html#nov-16th",
    "href": "Pratiti.html#nov-16th",
    "title": "2  Pratiti",
    "section": "10.3 nov 16th",
    "text": "10.3 nov 16th\n\n# Load necessary libraries\nlibrary(ggplot2)\n\n# Import the dataset\ndata &lt;- read.csv(\"education.csv\", header = TRUE, stringsAsFactors = FALSE)\n\n# Select only the relevant columns\nselected_data &lt;- data[, c(\"Educational.attainment\", \"Unemployment.rate....\")]\n\n# Rename columns for readability\ncolnames(selected_data) &lt;- c(\"Educational Attainment\", \"Unemployment Rate (%)\")\n\n# Convert Unemployment Rate to numeric (remove commas if needed)\nselected_data$`Unemployment Rate (%)` &lt;- as.numeric(gsub(\",\", \"\", selected_data$`Unemployment Rate (%)`))\n\n# Create a bar chart with gradient colors and no legend\nggplot(selected_data, aes(x = reorder(`Educational Attainment`, `Unemployment Rate (%)`), y = `Unemployment Rate (%)`, fill = `Unemployment Rate (%)`)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_gradient(low = \"lightblue\", high = \"darkblue\") +  # Gradient color from light to dark blue\n  labs(\n    title = \"Unemployment Rate by Educational Attainment\",\n    x = \"Educational Attainment\",\n    y = \"Unemployment Rate (%)\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for readability\n    legend.position = \"none\"  # Remove the legend\n  )\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_bar()`).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Pratiti</span>"
    ]
  },
  {
    "objectID": "Savannah.html",
    "href": "Savannah.html",
    "title": "3  Savannah",
    "section": "",
    "text": "3.1 Week 1\nexcel\n(note that I was not able to upload the photos to here) ### Wednesday\nACCESS THE WEB VERSION OF EXCEL THROUGH ONEDRIVE\n-cell is identified by a column letter and row number and holds a piece of data.\n-column is a vertical set of cells, identified by a letter.\n-row is a horizontal set of cells, identified by a number.\n=SUM() =AVERAGE() =MAX() =MIN()\ndouble click corner of box around a cell to make the formula go apply to the whole column\nuse control to select multiple specific cells/columns\nshift right control down to select\nuse &lt;&gt; to input a link in Quarto document\nuse to input a screenshot in a Quarto document MUST BE IN THE SAME FOLDER\nSCATTER PLOT EXAMPLE",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Savannah</span>"
    ]
  },
  {
    "objectID": "Savannah.html#week-1",
    "href": "Savannah.html#week-1",
    "title": "3  Savannah",
    "section": "",
    "text": "BASIC FUNCTIONS\n\nEXCEL NOTES\n\n\n\n\n\nBASIC PLOTS\n\n\n3.1.1 Friday\nMy data set is Rates of COVID-19 Cases or Deaths by Age Group and Vaccination Status from the Centers for Disease Control and Prevention website.\nDESCRIPTION OF DATA SET\nThis data set was posted on October 21, 2022 and was revised on February 22, 2023. The data reflect cases among people with a positive specimen collection date through September 24, 2022, and deaths among people with a positive specimen collection date through September 3, 2022.\nThe data was provided by the CDC COVID-19 Response, Epidemiology Task Force.\nThis data set has 1,591 rows and 16 columns.\nCOLUMNS IN DATA SET\nOUTCOME: case or death (text)\nMONTH: corresponding month to the MMWR week- MMM YYYY (text)\nMMWR week: the morbidity and mortality weekly report- YYYYWW (text)\nAGE GROUP: 0-5 (4 yrs), 5-11, 12-17, 18-29, 30-49, 50-64, 65-70, 80+ (text)\nVACCINE PRODUCT: Janssen, Moderna, Pfizer, all (text)\nVACCINATED WITH OUTCOME: weekly count of vaccinated individuals that correspond with an outcome (number)\nFULLY VACCINATED POPULATION: cumulative weekly count of the population vaccinated (number)\nUNVACCINATED WITH OUTCOME: weekly count of unvaccinated individuals that correspond with an outcome (number)\nUNVACCINATED POPULATION: cumulative weekly count of the population un-vaccinated (number)\nCRUDE VAX IR: incident rate for vaccinated population per 100,000 (number)\nCRUDE UNVAX IR: incident rate for un-vaccinated population per 100,000 (number)\nCRUDE IRR: incident rate ratio (un-vaccinated : vaccinated) (number)\nAGE ADJUSTED VAX IR: incident rate by age for vaccinated population per 100,000 (number)\nAGE ADJUSTED UNVAX IR: incident rate by age for un-vaccinated population per 100,000 (number)\nAGE ADJUSTED CRUDE IRR: incident rate ratio by age (un-vaccinated : vaccinated) (number)\nCONTINUITY CORRECTION: indicates whether the data was adjusted with the assumption that at least 5 percent of the population in the jurisdiction is un-vaccinated (number)\ndataset link: https://data.cdc.gov/Public-Health-Surveillance/Rates-of-COVID-19-Cases-or-Deaths-by-Age-Group-and/3rge-nu2a/about_data\nVISUALIZATIONS IN EXCEL OF DATASET\nHISTOGRAM\nThis visualization shows the weekly count of vaccinated individuals who have either the outcome of a case of covid or death by covid, grouped by age.\nLINE PLOT\nThis visualization shows a cumulative weekly count of the fully vaccinated population (teal) versus the un-vaccinated population (orange).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Savannah</span>"
    ]
  },
  {
    "objectID": "Savannah.html#week-2",
    "href": "Savannah.html#week-2",
    "title": "3  Savannah",
    "section": "3.2 week 2",
    "text": "3.2 week 2\n\n3.2.0.1 EXCEL: PIVOT TABLE AND CHART\n\n\n3.2.0.2 Documentation\nI am using the airquality data set which lists the daily numeric values of Ozone, Solar Radiation, Wind, and Temperature from the months of May to September in 1973 from the state of New York. The Ozone data was measured from Roosevelt Island, the Solar Radiation data was measured from Central Park, and the both the Wind and Temperature data was measured from the LaGuardia airport. This data was obtained from the New York State Department of Conservation, which provided the Ozone data, as well as the National Weather Service, which provided the meteorological data including the temperature, wind, and solar radiation values.\nI used excel to clean the data by removing all the rows with NA values, and performed exploration analysis with histograms and a pivot table and chart.\n\n\n3.2.0.3 Ozone Histogram\nIn-class example\n\n\n\n3.2.0.4 Ozonve vs Temp Scatter Plot\nIn-class example\n\n\n\n3.2.0.5 My first Pivot Table and Chart\n\nFrom my pivot table, I was able to take all the numerical data from the airquality data set and use a stacked line chart to compare the values of Ozone, Solar Radiation, Wind, and Temperature per day in the month of May. The line chart is colored by topic to make it easy to visually compare each topic as it changes per day. From this visualization, I was able to observe that the Wind and Temperature values remained relatively even throughout the month, while the Solar Radiation values became occasionally unstable, and the Ozone values changed drastically throughout the month.\n\n\n3.2.0.6 INDIVIDUAL PROJECT DOCUMENTATION\nMy data set is Rates of COVID-19 Cases or Deaths by Age Group and Vaccination Status from the Centers for Disease Control and Prevention website.\n\n\n3.2.0.7 Description of data set\nThis data set was posted on October 21, 2022 and was revised on February 22, 2023. The data reflect cases among people within various age groups with a positive specimen collection date through September 24, 2022, and deaths among people within those age groups with a positive specimen collection date through September 3, 2022.\nThe data was provided by the CDC COVID-19 Response, Epidemiology Task Force.\nThis data set has 1,591 rows and 16 columns.\n\n\n3.2.0.8 Purpose of data set\nThis information can be used by the CDC and pharmaceutical companies to see how affective the vaccine is in preventing Covid-19 cases, as well as to see if the vaccine helps prevent death once the virus is contracted.\nThis information can also be used to see if the vaccine is more correlated to preventing deaths or cases within specific age groups.\nThis information can be used by hospitals to predict the necessary number of beds and ventilators needed for patients.\nThis information can be used by insurance companies to determine how much money should be put aside to cover health/life insurance costs.\n\n\n3.2.0.9 Variables in data set and data type\nOUTCOME: case or death (text)\nMONTH: corresponding month to the MMWR week- MMM YYYY (text)\nMMWR week: the morbidity and mortality weekly report- YYYYWW (text)\nAGE GROUP: 0-5 (4 yrs), 5-11, 12-17, 18-29, 30-49, 50-64, 65-70, 80+ (text)\nVACCINE PRODUCT: Janssen, Moderna, Pfizer, all (text)\nVACCINATED WITH OUTCOME: weekly count of vaccinated individuals that correspond with an outcome (number)\nFULLY VACCINATED POPULATION: cumulative weekly count of the population vaccinated (number)\nUNVACCINATED WITH OUTCOME: weekly count of unvaccinated individuals that correspond with an outcome (number)\nUNVACCINATED POPULATION: cumulative weekly count of the population un-vaccinated (number)\nCRUDE VAX IR: incident rate for vaccinated population per 100,000 (number)\nCRUDE UNVAX IR: incident rate for un-vaccinated population per 100,000 (number)\nCRUDE IRR: incident rate ratio (un-vaccinated : vaccinated) (number)\nAGE ADJUSTED VAX IR: incident rate by age for vaccinated population per 100,000 (number)\nAGE ADJUSTED UNVAX IR: incident rate by age for un-vaccinated population per 100,000 (number)\nAGE ADJUSTED CRUDE IRR: incident rate ratio by age (un-vaccinated : vaccinated) (number)\nCONTINUITY CORRECTION: indicates whether the data was adjusted with the assumption that at least 5 percent of the population in the jurisdiction is un-vaccinated (number)\n\n\n3.2.0.10 Link to data set\nhttps://data.cdc.gov/Public-Health-Surveillance/Rates-of-COVID-19-Cases-or-Deaths-by-Age-Group-and/3rge-nu2a/about_data",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Savannah</span>"
    ]
  },
  {
    "objectID": "Savannah.html#week-3",
    "href": "Savannah.html#week-3",
    "title": "3  Savannah",
    "section": "3.3 Week 3",
    "text": "3.3 Week 3\n\n3.3.1 Wednesday\n\n\n3.3.2 Friday",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Savannah</span>"
    ]
  },
  {
    "objectID": "Savannah.html#week-4",
    "href": "Savannah.html#week-4",
    "title": "3  Savannah",
    "section": "3.4 Week 4",
    "text": "3.4 Week 4\n\n3.4.1 Wednesday and Friday\nimport numpy as np\narr = np.array([1,2,3,4,5])\nmy_list = [1, 2, 3, 4, 5]\nimport pandas as pd\ndata = {'Ozone': [41, 36, 12], 'Temp': [67, 72, 74]}\ndf = pd.DataFrame(data)\ndf = pd.read_csv('C:\\\\Users\\\\rdudley\\\\Downloads\\\\airquality_datasets.csv')\n# Summary of the dataset\nprint(df.info())\nprint(df.describe())\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 153 entries, 0 to 152\nData columns (total 6 columns):\n #   Column   Non-Null Count  Dtype  \n---  ------   --------------  -----  \n 0   Ozone    116 non-null    float64\n 1   Solar.R  146 non-null    float64\n 2   Wind     153 non-null    float64\n 3   Temp     153 non-null    int64  \n 4   Month    153 non-null    int64  \n 5   Day      153 non-null    int64  \ndtypes: float64(3), int64(3)\nmemory usage: 7.3 KB\nNone\n            Ozone     Solar.R        Wind        Temp       Month         Day\ncount  116.000000  146.000000  153.000000  153.000000  153.000000  153.000000\nmean    42.129310  185.931507    9.957516   77.882353    6.993464   15.803922\nstd     32.987885   90.058422    3.523001    9.465270    1.416522    8.864520\nmin      1.000000    7.000000    1.700000   56.000000    5.000000    1.000000\n25%     18.000000  115.750000    7.400000   72.000000    6.000000    8.000000\n50%     31.500000  205.000000    9.700000   79.000000    7.000000   16.000000\n75%     63.250000  258.750000   11.500000   85.000000    8.000000   23.000000\nmax    168.000000  334.000000   20.700000   97.000000    9.000000   31.000000\nimport matplotlib.pyplot as plt\n\n# Ozone Histogram\nplt.figure(figsize=(8, 6))\nplt.hist(df['Ozone'].dropna(), bins=20, color='blue', edgecolor='black')\nplt.title('Distribution of Ozone Levels')\nplt.xlabel('Ozone (ppb)')\nplt.ylabel('Frequency')\nplt.show()\n\n# Temp Histogram\nplt.figure(figsize=(8, 6))\nplt.hist(df['Temp'].dropna(), bins=20, color='orange', edgecolor='black')\nplt.title('Distribution of Temperature')\nplt.xlabel('Temperature (°F)')\nplt.ylabel('Frequency')\nplt.show()\n\n\n\npng\n\n\n\n\n\npng\n\n\n# Boxplot for Ozone\nplt.figure(figsize=(8, 6))\nplt.boxplot(df['Ozone'].dropna())\nplt.title('Boxplot of Ozone Levels')\nplt.ylabel('Ozone (ppb)')\nplt.show()\n\n# Boxplot for Temp\nplt.figure(figsize=(8, 6))\nplt.boxplot(df['Temp'].dropna())\nplt.title('Boxplot of Temperature')\nplt.ylabel('Temperature (°F)')\nplt.show()\n\n\n\npng\n\n\n\n\n\npng\n\n\nimport seaborn as sns\n\n# Scatter plot with regression line\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='Temp', y='Ozone', hue='Month', data=df)\nplt.title('Temperature vs Ozone Levels by Month')\nplt.xlabel('Temperature (°F)')\nplt.ylabel('Ozone (ppb)')\nplt.show()\n\n# Correlation matrix\ncorr = df[['Ozone', 'Temp', 'Wind']].corr()\nsns.heatmap(corr, annot=True, cmap='coolwarm')\nplt.title('Correlation Matrix')\nplt.show()\n\n\n\npng\n\n\n\n\n\npng",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Savannah</span>"
    ]
  },
  {
    "objectID": "Savannah.html#week-5",
    "href": "Savannah.html#week-5",
    "title": "3  Savannah",
    "section": "3.5 Week 5",
    "text": "3.5 Week 5",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Savannah</span>"
    ]
  },
  {
    "objectID": "Savannah.html#week-after-fall-break",
    "href": "Savannah.html#week-after-fall-break",
    "title": "3  Savannah",
    "section": "3.6 Week after fall break",
    "text": "3.6 Week after fall break",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Savannah</span>"
    ]
  },
  {
    "objectID": "Savannah.html#second-semester-schedule",
    "href": "Savannah.html#second-semester-schedule",
    "title": "3  Savannah",
    "section": "3.7 Second semester schedule",
    "text": "3.7 Second semester schedule\nAll charts made in r studio or shiny and 1-3 sentence summary with each visualization\nNov 2: create a bar chart comparing the number of workers, and their occupation\nNov 9: create a stacked area plot comparing gender distribution of workers in each occupation\nNov 16: create a dot plot comparing weekly earnings by their occupation\nNov 23: create a scatter plot comparing median weekly earnings vs number of workers\nNov 30: create a line chart comparing the gender pay gap across occupations\n(For this weeks assignment, everyone needed to find a dataset from our datasource and give a summary about it.)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Savannah</span>"
    ]
  },
  {
    "objectID": "Savannah.html#october-28th",
    "href": "Savannah.html#october-28th",
    "title": "3  Savannah",
    "section": "3.8 October 28th",
    "text": "3.8 October 28th",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Savannah</span>"
    ]
  },
  {
    "objectID": "Savannah.html#bar-chart",
    "href": "Savannah.html#bar-chart",
    "title": "3  Savannah",
    "section": "3.9 Bar Chart",
    "text": "3.9 Bar Chart\nVariables: Occupation and Total Number of Workers\n\n3.9.1 Import dataset\n\nlibrary(readxl)\ndata &lt;- read_excel(\"cpsaat39.xlsx\", range = \"A71:B82\", col_names = c(\"Occupations\", \"Total Number of Workers\"))\n\n\n\n3.9.2 Create Visualization\n\nlibrary(ggplot2)\nggplot(data, aes(x = reorder(Occupations, -`Total Number of Workers`), \n                 y = `Total Number of Workers`, \n                 fill = `Total Number of Workers`)) +\n  geom_bar(stat = \"identity\", color = \"black\", width = 0.8) +  # Add color and border\n  geom_text(aes(label = `Total Number of Workers`), \n            vjust = -0.3,  # Move labels higher above the bars\n            color = \"black\", size = 3.5) +  # Slightly larger font size for labels\n  scale_fill_gradient(low = \"lightblue\", high = \"darkblue\") +  # Gradient color for bars\n  labs(title = \"2023 US Total Number of Workers per IT Occupation\",\n       subtitle = \"Occupations sorted from highest to lowest number of workers by thousands\",\n       x = \"Occupations\",\n       y = \"Workers\") +\n  ylim(0, max(data$`Total Number of Workers`) * 1.2) +  # Expand y-axis limits\n  theme_minimal(base_size = 12) +  # Increase base font size\n  theme(\n    axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8),  # Adjust size for x-axis labels\n    axis.text.y = element_text(size = 8),  # Adjust size for y-axis numbers\n    axis.title.x = element_text(size = 10, margin = margin(t = 10), face = \"bold\"),  # X-axis title size and style\n    axis.title.y = element_text(size = 10, margin = margin(r = 10), face = \"bold\"),  # Y-axis title size and style\n    plot.title = element_text(face = \"bold\", size = 14, hjust = 0.5),  # Center-align title\n    plot.subtitle = element_text(size = 12, hjust = 0.5),              # Center-align subtitle\n    legend.position = \"none\"                                           # Remove legend\n  )",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Savannah</span>"
    ]
  },
  {
    "objectID": "Shae.html",
    "href": "Shae.html",
    "title": "4  Shae",
    "section": "",
    "text": "4.1 week 1",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#week-1",
    "href": "Shae.html#week-1",
    "title": "4  Shae",
    "section": "",
    "text": "4.1.1 Monday\nTutorial on excel function, sum,average. Go here &lt;\nCell is…… column is… row is….\n\n4.1.1.1 Basic Functions\nsum =sum(cell:cell)\nScatter Plot Insert graph by the insert tab adding a screenshot into a quarto\n\n\n\n4.1.1.2 Our own document\nmtcars\n\n\n4.1.1.3 Using the x,Census Data\n\n\n4.1.1.4 Description\nIt is a census of the poverty levels in California in the year of 2018\n\n\n4.1.1.5 Format\nThis data has 63 rows and 4 columns. [1] Label -&gt; categorical [2]population estimate -&gt; numerical [3]below poverty population estimate -&gt; numerical [4]percent below poverty -&gt; percentage\n#3 details Label - categorizing of population by different variables i.e age, ethnicity, race and sex population estimate - calculation of total population by categories under label below poverty population estimate- calculation of total population below poverty levels below poverty by categories under label percentage - calculation of percent of total population divided by total population below poverty\nSource https://data.census.gov/table/ACSST1Y2018.S1701?q=poverty%20in%20california%20in%202018\n\n\n4.1.1.6 Cleaning\nI removed the ratios as it only had the total popualtion seperated by age which was just a reiteration of the first few rows\nthere was an option of including the marginal error and I chose against that. I did not believe it was vital in explaining my data.\n\n\n4.1.1.7 Explanation\nThis data is has 71 rows, which divides my data into groups that are in the category of age, sex, race,highest level of education,employment status, work experience,and UNRELATED INDIVIDUALS FOR WHOM POVERTY STATUS IS DETERMINED\nThis data is has 4 columns that are filled with label and three estimate, each estimate is separated into the total in the group identified in the row and the amount that is below poverty as well as the percentage of the amount below poverty compared to the total in the category highlighted in the rows.\n  The above are the visualizations I chose to do to explain my data. The first is the distribution of poverty levels by gender to get a better understanding of the poverty levels in each gender before we break it up even further\nThe second is by age and I chose to include the overall population of each age group to understand the poverty levels against the overall population\nI also then made a pivot table chart with the education levels which makes the chart interchangeable and I can single out each education levels poverty rate\nThe 4th is among ethnicity if I continue using this data set the poverty among ethnicity is very important to understand and I also used a pie chart because it was the easiest to see which ethnicity has the most and compare them against one another.\nTotal homeless population against the total population just helps understand the overall populations of both before the deep dive\nLastly i just did the poverty levels against age without the total population because I believe age is the best way to describe the poverty levels.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#week-2",
    "href": "Shae.html#week-2",
    "title": "4  Shae",
    "section": "4.2 Week 2",
    "text": "4.2 Week 2\n\n4.2.0.1 Histograms\nI am using the air quality dataset, which is a measurement in New york from the months May to September 1973\n\n\n4.2.0.2 Format\nthis data has 153 observation and 6 variables but after cleaning it has 112 observations and six variables\n\n\n4.2.0.3 Source\nI got this data from d2l which was obtained from the New York State Department Of conservation\nI use excel to clean the data, remove all the NA which I used the filter tab to achieve.\n  This explains the average of ozone,solar,wind and temp pver the months which gives us a good idea of of which month was the highest and which had the stongest pull through the months.\n\nI chose maximum winds by the months and day to see their trend lind and which month going into specifically what day had the highest and lowest.\n I also did the average ozone by temp whichb gives an idea of what was happening in the ozone by different temps",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#week-3",
    "href": "Shae.html#week-3",
    "title": "4  Shae",
    "section": "4.3 Week 3",
    "text": "4.3 Week 3\n\n4.3.1 Wednesday\nPuromycin was my data set which is the study of the reaction verus the substrate concentration in an enzymatic reaction involving untreated cells or cells treated with Puromycin.The experiment was conducted once with the enzyme treated with Puromycin, and once with the enzyme untreated.\nThis dataset has 23 rows and 3 columns\nconc -&gt; a numeric vector of substrate concentrations (parts per million-ppm)\nrate/velocity -&gt; a numeric vector of instantaneous reaction rates, which was calculated from conc (counts/min/min)\nstate -&gt; a factor with levels treated untreated\nhttps://public.tableau.com/authoring/Week_3_Tableu_Mukurazhizha/Dashboard1#1\n\n\n4.3.2 Friday\n-Shae plans to work on a dashboard based on poverty data for specifically the state of oklahoma between Friday and Saturday-\n\n4.3.2.1 Using the x,Census Data\n\n\n4.3.2.2 Description\nIt is a census of the poverty levels in Oklahoma in the year of 2023\n\n\n4.3.2.3 Format\nThis data has 6 fields and 69 rows [1] Label -&gt; categorical [2]population estimate -&gt; numerical [3]below poverty population estimate -&gt; numerical [4]percent below poverty -&gt; percentage\n#3 details Label - categorizing of population by different variables i.e age, ethnicity, race and sex population estimate - calculation of total population by categories under label below poverty population estimate- calculation of total population below poverty levels below poverty by categories under label percentage - calculation of percent of total population divided by total population below poverty\nSource https://data.census.gov/table/ACSST1Y2023.S1701?q=poverty%20in%20oklahoma%20in%202023\n\n\n4.3.2.4 Cleaning\nUpon putting my data into Tableu I had to change all my numerical data into numerical from categorical.\nDashboard Links https://public.tableau.com/authoring/Ok_2023/Dashboard1#2\n\n\n4.3.2.5 Explanation",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#week-4",
    "href": "Shae.html#week-4",
    "title": "4  Shae",
    "section": "4.4 Week 4",
    "text": "4.4 Week 4\n\n4.4.1 Wednesday and Friday\nimport sys\nprint(sys.prefix)\n/home/csc477_00/venv477\nimport numpy as np\narr = np.array([1, 2, 3, 4, 5])\nmy_list = [1, 2, 3, 4, 5]\nimport pandas as pd\ndata = {'Ozone': [41, 36, 12], 'Temp': [67, 72, 74]}\ndf = pd.DataFrame(data)\ndf = pd.read_csv('path_to_file.csv')\n---------------------------------------------------------------------------\n\nFileNotFoundError                         Traceback (most recent call last)\n\nCell In[14], line 1\n----&gt; 1 df = pd.read_csv('path_to_file.csv')\n\n\nFile ~/venv477/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)\n   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\n\nFile ~/venv477/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\n\nFile ~/venv477/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\n\nFile ~/venv477/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\n\nFile ~/venv477/lib/python3.11/site-packages/pandas/io/common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\n\nFileNotFoundError: [Errno 2] No such file or directory: 'path_to_file.csv'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#week-5",
    "href": "Shae.html#week-5",
    "title": "4  Shae",
    "section": "4.5 Week 5",
    "text": "4.5 Week 5",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#week-after-fall-break",
    "href": "Shae.html#week-after-fall-break",
    "title": "4  Shae",
    "section": "4.6 Week after fall break",
    "text": "4.6 Week after fall break",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#second-semester-schedule",
    "href": "Shae.html#second-semester-schedule",
    "title": "4  Shae",
    "section": "4.7 Second Semester Schedule",
    "text": "4.7 Second Semester Schedule\nAll charts made in r studio or shiny and 1-3 sentence summary with each visualization\nNov 2: create a line chart comparing year with civilian labor force percent\nNov 9: create a stacked bar chart comparing employed agriculture and employed nonagricultural industries\nNov 16: create a line plot comparing year vs unemployed percent\nNov 23: create a dot plot comparing civilian labor force total and not in labor force\nNov 30: create a pie chart comparing workforce distribution in a specific year\n(For this weeks assignment, everyone needed to find a dataset from our datasource and give a summary about it.)\nThe dataset I chose is titled “Household Data Annual Averages” and it tracks the employment status of the civilian noninstitutional population in the U.S. from 1948 to the present. It includes various metrics in thousands of individuals, such as:\nCivilian Noninstitutional Population: Total number of people aged 16 and over not in military or institutional settings.\nCivilian Labor Force: Individuals who are either employed or unemployed, represented as a percentage of the population.\nEmployment and Unemployment: Counts and percentages of employed and unemployed individuals, differentiated by agriculture and nonagricultural industries.\nNot in Labor Force: Number of people not participating in the labor market.\nThe dataset highlights trends in labor force participation, employment rates, and unemployment over the decades, showing changes in economic conditions and labor market dynamics. For example, it reflects fluctuations in employment rates during economic recessions and expansions. The dataset is subject to revisions due to updates in population controls, which may impact historical comparisons.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#oct-28th",
    "href": "Shae.html#oct-28th",
    "title": "4  Shae",
    "section": "4.8 Oct 28th",
    "text": "4.8 Oct 28th",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#introduction",
    "href": "Shae.html#introduction",
    "title": "4  Shae",
    "section": "4.9 Introduction",
    "text": "4.9 Introduction\nThis document presents a visualization comparing the percentage of employed individuals and the unemployment rate over time. The analysis uses historical data on employment and unemployment metrics to provide insights into labor market dynamics.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#data-library-load",
    "href": "Shae.html#data-library-load",
    "title": "4  Shae",
    "section": "4.10 Data &Library Load",
    "text": "4.10 Data &Library Load",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#introduction-1",
    "href": "Shae.html#introduction-1",
    "title": "4  Shae",
    "section": "4.11 Introduction",
    "text": "4.11 Introduction\nThis document presents a visualization comparing the percentage of employed individuals and the unemployment rate over time. The analysis uses historical data on employment and unemployment metrics to provide insights into labor market dynamics.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#data-library-load-1",
    "href": "Shae.html#data-library-load-1",
    "title": "4  Shae",
    "section": "4.12 Data &Library Load",
    "text": "4.12 Data &Library Load\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(readxl)\nlibrary(tidyr)\nlibrary(readr)  # If you're reading CSV or similar formats\nlibrary(ggplot2)\n\n\ndata2 &lt;- read_excel(\"LineGraph.xlsx\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#data-clean-and-prepartion",
    "href": "Shae.html#data-clean-and-prepartion",
    "title": "4  Shae",
    "section": "4.13 Data Clean and Prepartion",
    "text": "4.13 Data Clean and Prepartion\n\ndata_clean &lt;- data2 %&gt;%\n  select(Year, `Total`, `Unemployed Percent\\r\\nof\\r\\nlabor\\r\\nforce`) %&gt;%\n  rename(\n    Employed_Total = `Total`,\n    Unemployed_Percent = `Unemployed Percent\\r\\nof\\r\\nlabor\\r\\nforce`\n  ) %&gt;%\n  mutate(\n    Employed_Total = as.numeric(Employed_Total),\n    Unemployed_Percent = as.numeric(Unemployed_Percent)\n  )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#visualization",
    "href": "Shae.html#visualization",
    "title": "4  Shae",
    "section": "4.14 Visualization",
    "text": "4.14 Visualization\n\nggplot(data_clean, aes(x = Employed_Total, y = Unemployed_Percent)) +\n  geom_line(color = \"darkgreen\", size = 1.2) +  # Change line color\n  labs(\n    title = \"Unemployed vs. Employed\",\n    x = \"Employed\",  # Updated x-axis title\n    y = \"Unemployed\"  # Updated y-axis title\n  ) +\n  theme_minimal(base_size = 15) +  # Increase base font size\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20, face = \"bold\", color = \"black\"),  # Center title, change font size and color\n    axis.title.x = element_text(size = 16, face = \"bold\", color = \"#0072B2\"),  # X-axis title\n    axis.title.y = element_text(size = 16, face = \"bold\", color = \"#0072B2\"),  # Y-axis title\n    axis.text = element_text(size = 14)  # Axis text size\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_line()`).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#summary-of-visualization",
    "href": "Shae.html#summary-of-visualization",
    "title": "4  Shae",
    "section": "4.15 Summary of Visualization",
    "text": "4.15 Summary of Visualization\nThis line chart illustrates the relationship between the percentage of employed individuals and the unemployment rate over time. Specifically, it compares the Employed Percentage (representing the proportion of the civilian labor force that is employed) against the Unemployed Percentage (indicating the proportion of the labor force that is unemployed).\nKey Points: Trends Over Time: The chart shows how both employment and unemployment rates have evolved from the data’s starting year to the present. Inverse Relationship: Generally, as the percentage of employed individuals increases, the unemployment rate tends to decrease, indicating an inverse relationship between these two metrics. Economic Insights: The visualization provides insights into economic conditions and labor market dynamics, highlighting periods of growth and recession based on employment trends.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#nov-16th",
    "href": "Shae.html#nov-16th",
    "title": "4  Shae",
    "section": "4.16 nov 16th",
    "text": "4.16 nov 16th",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#data-library-load-2",
    "href": "Shae.html#data-library-load-2",
    "title": "4  Shae",
    "section": "5.1 Data &Library Load",
    "text": "5.1 Data &Library Load\n\nlibrary(dplyr)\nlibrary(readxl)\nlibrary(tidyr)\nlibrary(readr)  # If you're reading CSV or similar formats\nlibrary(ggplot2)\n\n\ndata &lt;- read_excel(\"LineGraph.xlsx\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#data-clean-and-prepartion-1",
    "href": "Shae.html#data-clean-and-prepartion-1",
    "title": "4  Shae",
    "section": "5.2 Data Clean and Prepartion",
    "text": "5.2 Data Clean and Prepartion\n\ndata_clean &lt;- data %&gt;%\n  select(Year, `Total`, `Unemployed Percent\\r\\nof\\r\\nlabor\\r\\nforce`) %&gt;%\n  rename(\n    Employed_Total = `Total`,\n    Unemployed_Percent = `Unemployed Percent\\r\\nof\\r\\nlabor\\r\\nforce`\n  ) %&gt;%\n  mutate(\n    Employed_Total = as.numeric(Employed_Total),\n    Unemployed_Percent = as.numeric(Unemployed_Percent)\n  )",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#visualization-1",
    "href": "Shae.html#visualization-1",
    "title": "4  Shae",
    "section": "5.3 Visualization",
    "text": "5.3 Visualization\n\nggplot(data_clean, aes(x = Employed_Total, y = Unemployed_Percent)) +\n  geom_line(color = \"darkgreen\", size = 1.2) +  # Change line color\n  labs(\n    title = \"Unemployed vs. Employed\",\n    x = \"Employed\",  # Updated x-axis title\n    y = \"Unemployed\"  # Updated y-axis title\n  ) +\n  theme_minimal(base_size = 15) +  # Increase base font size\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 20, face = \"bold\", color = \"black\"),  # Center title, change font size and color\n    axis.title.x = element_text(size = 16, face = \"bold\", color = \"#0072B2\"),  # X-axis title\n    axis.title.y = element_text(size = 16, face = \"bold\", color = \"#0072B2\"),  # Y-axis title\n    axis.text = element_text(size = 14)  # Axis text size\n  )\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_line()`).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  },
  {
    "objectID": "Shae.html#summary-of-visualization-1",
    "href": "Shae.html#summary-of-visualization-1",
    "title": "4  Shae",
    "section": "5.4 Summary of Visualization",
    "text": "5.4 Summary of Visualization\nThis line chart illustrates the relationship between the percentage of employed individuals and the unemployment rate over time. Specifically, it compares the Employed Percentage (representing the proportion of the civilian labor force that is employed) against the Unemployed Percentage (indicating the proportion of the labor force that is unemployed).\nKey Points: Trends Over Time: The chart shows how both employment and unemployment rates have evolved from the data’s starting year to the present. Inverse Relationship: Generally, as the percentage of employed individuals increases, the unemployment rate tends to decrease, indicating an inverse relationship between these two metrics. Economic Insights: The visualization provides insights into economic conditions and labor market dynamics, highlighting periods of growth and recession based on employment trends.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Shae</span>"
    ]
  }
]